{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "projet_exploradome_model_1.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "e35WwOdJlmLI",
        "CQ5KjNPmrAOz",
        "9qxs1JZ1nbn7",
        "llekFJhbBwon",
        "cZCUcmV3j56C",
        "eliVxg1eSbxS"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lydiahiba/exploradome_tangram/blob/cnn---team-2/projet_exploradome_model_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utExesmuTvDb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pour commencer installer le weight and baias (wandb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_rWNE9XT9-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kP7ATlClhW6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import math\n",
        "import datetime\n",
        "from fastai.vision import *\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmBmZ_EdkzxC",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1qiEBHFkyul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hyper params\n",
        "# Set up your default hyperparameters before wandb.init\n",
        "# so they get properly set in the sweep\n",
        "hyperparameter_defaults = dict(\n",
        "    dropout = 0.25,\n",
        "    channels_one = 32,\n",
        "    channels_two = 32,\n",
        "    batch_size = 32,\n",
        "    decay = 0.0, \n",
        "    earlyStopPatience = 10,\n",
        "    trainRatio = 0.8,\n",
        "    beta_1 = 0.9,\n",
        "    beta_2 = 0.999,\n",
        "    dense_layer_nodes = 256,\n",
        "    learning_rate = 0.01/3,\n",
        "    epochs = 50,\n",
        "    #optimizer = tf.optimizers.Adamax(lr = config.learning_rate),\n",
        "    splitt = [0.2, 0,3], \n",
        "    activation_function = ['softmax', 'softplus', 'softsign', 'tanh' ],\n",
        "    size_img = 250\n",
        "  \n",
        "    )\n",
        "\n",
        "# Pass your defaults to wandb.init\n",
        "wandb.init(config=hyperparameter_defaults)\n",
        "config = wandb.config\n",
        "\n",
        "\n",
        "# Log metrics inside your training loop\n",
        "# metrics = {'accuracy': accuracy, 'loss': loss}\n",
        "# wandb.log(metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGeJ-UhbJ6uq",
        "colab_type": "text"
      },
      "source": [
        "## Connect in google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgACTbZ-F7HW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Google drive\n",
        "%cd ..\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Suo_KIeG8El_",
        "colab_type": "text"
      },
      "source": [
        "## Unzip file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kABpaBICFBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ln -s /content/gdrive/My\\ Drive/ /mydrive\n",
        "!ls /mydrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVwJCAqy6LqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creata directory videos\n",
        "# os.makedirs(\"data\", exist_ok=True)\n",
        "# !mv data /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyekVs2sIEn5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brYykWzhCJYB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !unzip \"/content/gdrive/My Drive/Exploradome/Dataset/Train-set.zip\" -d \"/content/train\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7ilIisc9gk1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !unzip \"/content/gdrive/My Drive/Exploradome/Dataset/Valid_images.zip\" -d \"/content/val\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LxYyCeer1-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !unzip \"/content/gdrive/My Drive/Exploradome/Dataset/Test.zip\" -d \"/content\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_-E4GgpKQZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saAkjr1yreFX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.makedirs('val3',exist_ok=True)\n",
        "!mv val3 /content \n",
        "!unzip \"/content/gdrive/My Drive/Exploradome Project /Copie de Valid_images.zip\" -d \"/content/val3\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WU54OVdqqvQT",
        "colab_type": "text"
      },
      "source": [
        "## Create labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyUTiXfrzDX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create labels and path\n",
        "TRAIN = (\"/content/gdrive/My Drive/Dataset-gp2/Train-set\")\n",
        "VAL = (\"/content/gdrive/My Drive/Dataset-gp2/Valid-set\")\n",
        "TEST = (\"/content/gdrive/My Drive/Dataset-gp2/Test-set\")\n",
        "VAL3=(\"/content/val3\")\n",
        "Labels = ['Bateau', 'Bol', 'Chat', 'Coeur', 'Cygne', 'Lapin', 'Maison', 'Marteau', 'Montagne', 'Pont', 'Renard','Tortue']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqxdEk9b1195",
        "colab_type": "text"
      },
      "source": [
        "# Image per label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kckjyMo62N75",
        "colab_type": "text"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSAU92i111A6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in os.listdir(\"/content/gdrive/My Drive/Dataset-gp2/Train-set\"):\n",
        " print(\"/content/gdrive/My Drive/Dataset-gp2/Train-set\"+\"/\"+i)\n",
        " print(len(os.listdir(\"/content/gdrive/My Drive/Dataset-gp2/Train-set\"+\"/\"+i))) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDZOSHaw2R1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in os.listdir(\"/content/gdrive/My Drive/Dataset-gp2/Train-set\"):\n",
        " print(\"/content/gdrive/My Drive/Dataset-gp2/Train-set\"+\"/\"+i)\n",
        " print(len(os.listdir(\"/content/gdrive/My Drive/Dataset-gp2/Train-set\"+\"/\"+i)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7MhQhTAlRvL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show img train\n",
        "for label in Labels:\n",
        "    path = os.path.join(TRAIN, label)\n",
        "    for img in os.listdir(path):\n",
        "        img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
        "        print(os.path.join(path, img))\n",
        "        plt.imshow(img_array, cmap=\"gray\")\n",
        "        plt.title(Labels[os.listdir(path).index(img)])\n",
        "        plt.show()\n",
        "        break\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BZWy17i_Rkh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show img test\n",
        "for label in Labels:\n",
        "    path = os.path.join(VAL, label)\n",
        "    for img in os.listdir(path):\n",
        "        img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
        "        print(os.path.join(path, img))\n",
        "        plt.imshow(img_array, cmap=\"gray\")\n",
        "        plt.title(Labels[os.listdir(path).index(img)])\n",
        "        plt.show()\n",
        "        break\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e35WwOdJlmLI",
        "colab_type": "text"
      },
      "source": [
        "## Create data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ADUes0sllhG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def creat_train_data(PATH):\n",
        "  data = []\n",
        "  images = []\n",
        "  targets = []\n",
        "\n",
        "  IMG_SIZE = tuple((config.size_img, config.size_img))\n",
        "  for label in Labels:\n",
        "      path = os.path.join(PATH, label)  \n",
        "      index_ = Labels.index(label)\n",
        "      for img in os.listdir(path):\n",
        "          try:\n",
        "              img_array = cv2.imread(os.path.join(path, img))\n",
        "              new_array = cv2.resize(img_array, IMG_SIZE, interpolation=cv2.INTER_AREA)\n",
        "              imgGray = cv2.cvtColor(new_array, cv2.COLOR_BGR2GRAY)\n",
        "              imgGray_flat=np.array(imgGray).flatten()\n",
        "              images.append(imgGray)\n",
        "              targets.append(index_)\n",
        "              data.append(imgGray_flat)\n",
        "          except Exception as e:\n",
        "              print(e)\n",
        "  return data, images, targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPuanyBoDu6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Train, Images, Targets = creat_train_data(TRAIN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9L05vCCsR69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(Images))\n",
        "print(len(Train))\n",
        "print(len(Targets))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6rDQQAdClTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Val, val_images, val_targets  = creat_train_data(VAL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRb2NrJosWDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(Val))\n",
        "print(len(val_images))\n",
        "print(len(val_targets))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpbF-zxmsudV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test, tes_images, test_targets  = creat_train_data(TEST)\n",
        "print(len(test))\n",
        "print(len(tes_images))\n",
        "print(len(test_targets))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBYo84yjsVhz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val3, val3_images, val3_targets  = creat_train_data(VAL3)\n",
        "print(len(val3))\n",
        "print(len(val3_images))\n",
        "print(len(val3_targets))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQ5KjNPmrAOz",
        "colab_type": "text"
      },
      "source": [
        "## List to array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl1nI0Mwq4lu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def toarray(liste):\n",
        "  arr = np.array(liste)\n",
        "  print(arr.shape)\n",
        "  return arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiB45u-om0rv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# transform data train to numpy array\n",
        "Images = toarray(Images)\n",
        "Train = toarray(Train)\n",
        "Targets = toarray(Targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEBeZ-gAGd8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# transform val to numpy array\n",
        "Val = toarray(Val)\n",
        "val_images = toarray(val_images)\n",
        "val_targets = toarray(val_targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYlGQkYitvuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# transform val to numpy array\n",
        "test = toarray(test)\n",
        "tes_images = toarray(tes_images)\n",
        "test_targets = toarray(test_targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFmqD9-dBGx1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# transform val to numpy array\n",
        "test = toarray(val3)\n",
        "tes_images = toarray(val3_images)\n",
        "test_targets = toarray(val3_targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYdVr4aZnvp4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(Images[3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qxs1JZ1nbn7",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9jTAk16y-vP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# facilité les calcules\n",
        "def preprocess_image(img):\n",
        "    return img / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZPCyQ1ipYCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# preprocessing image_train\n",
        "train = []\n",
        "for i in range(len(Images)):\n",
        "    train.append(preprocess_image(Images[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLidc7BaA4YY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Apres \n",
        "train[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q13sZxUID-09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# transform train to numpy array\n",
        "train = toarray(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "th7IckqPBByy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# preprocessing images_test\n",
        "val = []\n",
        "for i in range(len(val_images)):\n",
        "    val.append(preprocess_image(val_images[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XZk0UXeBMMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val = toarray(val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ikW2z0PBpsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_K3xeoYeuRlJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# preprocessing images_test\n",
        "Test = []\n",
        "for i in range(len(tes_images)):\n",
        "    Test.append(preprocess_image(tes_images[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJDFsh-tuU5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Test = toarray(Test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS7skfdWBPc8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# preprocessing images_test\n",
        "Val3 = []\n",
        "for i in range(len(val3_images)):\n",
        "    Val3.append(preprocess_image(val3_images[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSVb-Kywtrut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Val3 = toarray(Val3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQya6dlm3SaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot some image in data\n",
        "for i in range(len(train[100:108])):\n",
        "  plt.imshow(train[102+i].reshape(config.size_img, config.size_img), cmap=\"gray\")\n",
        "  plt.title(Labels[Targets[102+i]])\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llekFJhbBwon",
        "colab_type": "text"
      },
      "source": [
        "## Split data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqR1VvGEsuvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNIpq2onstCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split data \n",
        "def split(X, y):\n",
        "  xtr, xtes, ytr, ytes = train_test_split(X, y, test_size=config.splitt[0], random_state=42)\n",
        "  print(f'shape of train: {xtr.shape} \\n shape of test: {xtes.shape} \\n shape of target train: {ytr.shape} \\n shape of target test: {ytes.shape}')\n",
        "  return xtr, xtes, ytr, ytes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZCUcmV3j56C",
        "colab_type": "text"
      },
      "source": [
        "## Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuoFLXnSrmD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKdbZbY3r2TP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(9,9))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6o-YPuGuemZ",
        "colab_type": "text"
      },
      "source": [
        "## Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFf_u1DkcEQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.makedir('Models',exist_ok=True)\n",
        "!mv Models / content "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8D-9lnUBuhRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ma fonction Main\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    # Fonction main\n",
        "    \"\"\"\n",
        "\n",
        "    #Definition des chemins et autres variables\n",
        "    # pathData = '/content/gdrive/My Drive/model4'\n",
        "    # trainRatio = 0.8\n",
        "    # epochs = 30\n",
        "    # batch_size = 32\n",
        "    # earlyStopPatience = 10\n",
        "\n",
        "\n",
        "    #Definition des callbacks\n",
        "\n",
        "    #Permet de retourner 4 metrics de suivi a chaque iteration\n",
        "    csv_logger = tf.keras.callbacks.CSVLogger('/content/gdrive/My Drive/Models/log_Model4.csv', append=True, separator=',')\n",
        "\n",
        "    #Permet de stopper l'entrainement quand le modèle n'entraine plus\n",
        "    early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta = 0, patience = config.earlyStopPatience, verbose=0, mode='auto')\n",
        "\n",
        "    #Permet de sauvegarder le model a chaque iteration si il est meilleur que le precedent\n",
        "    check = tf.keras.callbacks.ModelCheckpoint('/content/gdrive/My Drive/Models/Model4.h5', monitor='val_loss', verbose=0,\n",
        "                            save_best_only=True, save_weights_only=False, mode='auto')\n",
        "\n",
        "    #Recuperation de nos data pré traité\n",
        "    # split data images\n",
        "    print('-----------------------------------------------------split data images---------------------------------------------------------')\n",
        "    img_train, img_test, target_train, target_test =  split(train, Targets)\n",
        "\n",
        "    #On verifie les dimensions de nos données\n",
        "    # print('DIMENSION img TRAIN ' + str(img_train.shape))\n",
        "    # print('DIMENSION img TEST ' + str(img_test.shape))\n",
        "    # print('DIMENSION target TRAIN ' + str(target_train.shape))\n",
        "    # print('DIMENSION target TEST ' + str(target_test.shape))\n",
        "\n",
        "    # reshape data to have a single channel\n",
        "    img_train = img_train.reshape((img_train.shape[0], img_train.shape[1], img_train.shape[2], 1))\n",
        "    img_test = img_test.reshape((img_test.shape[0], img_test.shape[1], img_test.shape[2], 1))\n",
        "\n",
        "    # new dimension of data\n",
        "    print('\\n')\n",
        "    print('-----------------------------------------------------dimension of data---------------------------------------------------------')\n",
        "    print(f'img_train shape : {img_train.shape}')\n",
        "    print(f'img_test shape : {img_test.shape}')\n",
        "\n",
        "    # determiné le shape of the input images\n",
        "    in_shape = img_train.shape[1:]\n",
        "\n",
        "    # determine the number of classes\n",
        "    print('\\n')\n",
        "    print('-----------------------------------------------------number of classes---------------------------------------------------------')\n",
        "    n_classes = len(np.unique(target_train))\n",
        "    print(f'Input image : {in_shape}, Les classes :{n_classes}')\n",
        "\n",
        "    # ------------------------ On creer le modele\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(config.channels_one, kernel_size=(9, 9), activation='relu', padding=\"Same\", strides=(1,1), kernel_initializer='he_uniform', input_shape=img_train.shape[1:] ) )\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(config.dropout))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(config.channels_two, kernel_size=(3,3), padding=\"Same\", activation='relu', strides=(1,1), kernel_initializer='he_uniform'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(tf.keras.layers.Dropout(config.dropout))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(config.channels_two, kernel_size=(3,3), padding=\"Same\", activation='relu', strides=(1,1), kernel_initializer='he_uniform'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(tf.keras.layers.Dropout(config.dropout))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(config.dense_layer_nodes, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(config.dropout))\n",
        "    model.add(tf.keras.layers.Dense(n_classes, activation = config.activation_function[0]))\n",
        "    # ------------------------- END -------------------------\n",
        "    \n",
        "    # Add the optimizer\n",
        "    # step = tf.Variable(0, trainable=False)\n",
        "    # rate = tf.train.exponential_decay(0.15, step, 1, 0.9999)\n",
        "    # optimizer = tf.train.AdamOptimizer(rate).minimize(cross_entropy, global_step=step)\n",
        "\n",
        "\n",
        "    # On compile le modele\n",
        "    model.compile(loss = tf.losses.SparseCategoricalCrossentropy(),\n",
        "                  optimizer= tf.optimizers.Adamax(lr = config.learning_rate), \n",
        "                  metrics = ['accuracy'])\n",
        "    \n",
        "    # On lance l'entrainement du modele\n",
        "    print('\\n')\n",
        "    print('-----------------------------------------------------Training Model---------------------------------------------------------')\n",
        "    wandb.init()\n",
        "    trainning = model.fit(img_train, target_train, \n",
        "                          batch_size = config.batch_size,\n",
        "                          epochs = config.epochs, \n",
        "                          validation_data = (img_test, target_test))\n",
        "                          # callbacks = [WandbCallback()])\n",
        "                          #callbacks = [early, check,csv_logger] )\n",
        "    print('\\n')\n",
        "    print('---------------------------------------------------------HISTORY LOSS---------------------------------------------------------------')\n",
        "\n",
        "    loss_curve = trainning.history[\"loss\"]\n",
        "    loss_val_curve = trainning.history[\"val_loss\"]\n",
        "    plt.plot(loss_curve, label=\"Train\")\n",
        "    plt.plot(loss_val_curve, label=\"Val\")\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.title(\"Loss\")\n",
        "    plt.show()\n",
        "\n",
        "    print('\\n')\n",
        "    print('---------------------------------------------------------HISTORY ACC---------------------------------------------------------------')\n",
        "    acc_curve = trainning.history[\"accuracy\"]\n",
        "    acc_val_curve = trainning.history[\"val_accuracy\"]\n",
        "\n",
        "    plt.plot(acc_curve, label=\"Train\")\n",
        "    plt.plot(acc_val_curve, label=\"Val\")\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.title(\"Accuracy\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    print('\\n')\n",
        "    print('------------------------------------------------------- TEST MODEL --------------------------------------------------------')\n",
        "    loss, acc = model.evaluate(img_test, target_test)\n",
        "    print(\"Test Loss\", loss)\n",
        "    print(\"Test Accuracy\", acc)\n",
        "    print('\\n')\n",
        "\n",
        "    print('----------------------------------------------------Evaluation model avec Val 1----------------------------------------------------')\n",
        "    # reshape data to have a single channel\n",
        "    eval = val.reshape((val.shape[0], val.shape[1], val.shape[2], 1))\n",
        "    loss, acc = model.evaluate(eval, val_targets)\n",
        "    print(\"Test Loss\", loss)\n",
        "    print(\"Test Accuracy\", acc)\n",
        "    print('\\n')\n",
        "\n",
        "    print('----------------------------------------------------Evaluation model avec Val 2----------------------------------------------------')\n",
        "    # reshape data to have a single channel\n",
        "    eval2 = Test.reshape((Test.shape[0], Test.shape[1], Test.shape[2], 1))\n",
        "    loss_2, acc_2 = model.evaluate(eval2, test_targets)\n",
        "    print(\"Test Loss\", loss_2)\n",
        "    print(\"Test Accuracy\", acc_2)\n",
        "\n",
        "    # print('----------------------------------------------------Evaluation model avec Val 3----------------------------------------------------')\n",
        "    # # reshape data to have a single channel\n",
        "    # eval3 = Test.reshape((Val3.shape[0], Val3.shape[1], Val3.shape[2], 1))\n",
        "    # loss_3, acc_3 = model.evaluate(eval3,val3_targets )\n",
        "    # print(\"Test Loss\", loss_3)\n",
        "    # print(\"Test Accuracy\", acc_3)\n",
        "\n",
        "\n",
        "    print('\\n')\n",
        "    print('----------------------------------------------------------CONFUSION MATRIX val1-------------------------------------------------------------------')\n",
        "    Y_pred_2 = model.predict_generator(eval)\n",
        "    y_pred_2 = np.argmax(Y_pred_2, axis=1)\n",
        "\n",
        "    cm_2 = confusion_matrix(y_true=val_targets, y_pred=y_pred_2)\n",
        "    cm_plot_labels = Labels\n",
        "    plot_confusion_matrix(cm=cm_2, classes=cm_plot_labels, title='Confusion Matrix')\n",
        "\n",
        "    print('\\n')\n",
        "    print('----------------------------------------------------------CONFUSION MATRIX val2-------------------------------------------------------------------')\n",
        "    Y_pred_2_ = model.predict_generator(eval2)\n",
        "    y_pred_2_ = np.argmax(Y_pred_2_, axis=1)\n",
        "\n",
        "    cm_2_ = confusion_matrix(y_true = test_targets, y_pred = y_pred_2_)\n",
        "    cm_plot_labels_ = Labels\n",
        "    plot_confusion_matrix(cm = cm_2_, classes=cm_plot_labels_, title ='Confusion Matrix')\n",
        "    print('\\n')\n",
        "\n",
        "    # print('----------------------------------------------------------CONFUSION MATRIX val3-------------------------------------------------------------------')\n",
        "    # Y_pred_3 = model.predict_generator(eval3)\n",
        "    # y_pred_3 = np.argmax(Y_pred_3, axis=1)\n",
        "\n",
        "    # cm_3 = confusion_matrix(y_true =val3_targets , y_pred = Y_pred_3)\n",
        "    # cm_plot_labels3 = Labels\n",
        "    # plot_confusion_matrix(cm = cm_3, classes=cm_plot_labels3, title ='Confusion Matrix')\n",
        "    # print('\\n')\n",
        "    print('----------------------------------------------------------Model Saving-------------------------------------------------------------------')\n",
        "\n",
        "    model.save(\"/content/model_tuned.h5\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\"\n",
        "    # MAIN\n",
        "    \"\"\"\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eliVxg1eSbxS",
        "colab_type": "text"
      },
      "source": [
        "## Check its architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3I-vn3lR0kh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGzhXxdzEkn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.read_csv('/content/gdrive/My Drive/model4/log_Model4.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H8PkgA5K2gi",
        "colab_type": "text"
      },
      "source": [
        "# Loading the saved Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "008yALPDJ3G7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/content/model_tuned.h5\")\n",
        "\n",
        "# loaded_model=tf.keras.models.load_model(\"my_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xt70i5wLAV5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}